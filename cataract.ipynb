{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cataract.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSdokOGN8Z4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D,Dense,MaxPool2D,Flatten,BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from math import hypot,sqrt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce46qlwC8eIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "0f8cf8a6-03c8-4b08-af05-baeb8963026b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6jjzyjJ_wFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bcd38053-cab5-428b-ad83-4278605a76b0"
      },
      "source": [
        "shape=(64,64)\n",
        "root_path=\"/content/drive/My Drive/datasets/cataract dataset/\"\n",
        "train_gen = ImageDataGenerator(\n",
        "        rescale=1 / 255.0,\n",
        "        rotation_range=20,\n",
        "        zoom_range=0.05,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        shear_range=0.05,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\",\n",
        "        validation_split=0.20)\n",
        "test_gen=ImageDataGenerator(rescale=1/255.0)\n",
        "train_data_gen=train_gen.flow_from_directory(root_path+'training/',\n",
        "                                             target_size=shape,\n",
        "                                             color_mode='grayscale',\n",
        "                                             class_mode='categorical',\n",
        "                                             batch_size=8\n",
        "                                             )\n",
        "test_data_gen=test_gen.flow_from_directory(root_path+'testing/',\n",
        "                                               target_size=shape,\n",
        "                                             color_mode='grayscale',\n",
        "                                             class_mode='categorical',\n",
        "                                             batch_size=8)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 340 images belonging to 2 classes.\n",
            "Found 55 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdb6lYADzfVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nueral Network\n",
        "model=Sequential()\n",
        "model.add(Conv2D(128,(2,2),activation='relu',input_shape=(shape[0],shape[1],1)))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128,(2,2),activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64,(2,2),activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(28,activation='relu'))\n",
        "model.add(Dense(2,activation='sigmoid'))\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDoHcnjxzfrs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52a0a2f6-69fc-4508-9cc8-ccf95b2eeb5a"
      },
      "source": [
        "opt=optimizers.SGD(learning_rate=0.01,momentum=0.58)\n",
        "model.compile(optimizer=opt,loss=\"BinaryCrossentropy\",metrics=['accuracy'])\n",
        "model.fit_generator(train_data_gen,steps_per_epoch=25,epochs=30,validation_data=test_data_gen)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.7017 - accuracy: 0.6600 - val_loss: 0.6898 - val_accuracy: 0.5273\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 0.6043 - accuracy: 0.6786 - val_loss: 0.6960 - val_accuracy: 0.5273\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 0.6228 - accuracy: 0.6939 - val_loss: 0.6866 - val_accuracy: 0.5273\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4948 - accuracy: 0.7704 - val_loss: 0.6932 - val_accuracy: 0.5273\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 0.5193 - accuracy: 0.7296 - val_loss: 0.6740 - val_accuracy: 0.5273\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.5206 - accuracy: 0.7245 - val_loss: 0.6706 - val_accuracy: 0.5273\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.4624 - accuracy: 0.7900 - val_loss: 0.6699 - val_accuracy: 0.5273\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 0.5415 - accuracy: 0.7449 - val_loss: 0.6323 - val_accuracy: 0.7091\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4630 - accuracy: 0.7900 - val_loss: 0.7943 - val_accuracy: 0.5273\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.4782 - accuracy: 0.7950 - val_loss: 0.6292 - val_accuracy: 0.6182\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4791 - accuracy: 0.7959 - val_loss: 0.5895 - val_accuracy: 0.6909\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 0.4766 - accuracy: 0.7602 - val_loss: 0.6486 - val_accuracy: 0.6182\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 0.4082 - accuracy: 0.8050 - val_loss: 0.9100 - val_accuracy: 0.5273\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.4121 - accuracy: 0.8250 - val_loss: 0.5252 - val_accuracy: 0.7636\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4276 - accuracy: 0.8010 - val_loss: 0.6872 - val_accuracy: 0.6727\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 0.3749 - accuracy: 0.8200 - val_loss: 0.5156 - val_accuracy: 0.7636\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.3313 - accuracy: 0.8673 - val_loss: 0.6848 - val_accuracy: 0.7091\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 0.3981 - accuracy: 0.8200 - val_loss: 0.5705 - val_accuracy: 0.7455\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.3882 - accuracy: 0.8400 - val_loss: 0.5389 - val_accuracy: 0.7273\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4186 - accuracy: 0.8150 - val_loss: 0.5234 - val_accuracy: 0.7273\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 0.4211 - accuracy: 0.8163 - val_loss: 0.5553 - val_accuracy: 0.7818\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 0.2865 - accuracy: 0.8827 - val_loss: 0.5787 - val_accuracy: 0.7091\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4132 - accuracy: 0.8061 - val_loss: 0.5996 - val_accuracy: 0.7455\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 0.3345 - accuracy: 0.8800 - val_loss: 0.6842 - val_accuracy: 0.7455\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.3484 - accuracy: 0.8350 - val_loss: 0.9199 - val_accuracy: 0.7091\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 0.2988 - accuracy: 0.8776 - val_loss: 0.6364 - val_accuracy: 0.8182\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.3307 - accuracy: 0.8520 - val_loss: 0.5705 - val_accuracy: 0.7455\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.3129 - accuracy: 0.8469 - val_loss: 0.6684 - val_accuracy: 0.7455\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.3105 - accuracy: 0.8827 - val_loss: 0.6757 - val_accuracy: 0.7818\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.2649 - accuracy: 0.9031 - val_loss: 0.6419 - val_accuracy: 0.6909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faac3e3dc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyAFLBt3zgAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "1daf0e9b-5988-40ed-f146-5343e1fb9196"
      },
      "source": [
        "pred=model.predict_generator(test_data_gen,steps=10,use_multiprocessing=True,verbose=1)\n",
        "np.argmax(pred,axis=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            " 5/10 [==============>...............] - ETA: 0sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "10/10 [==============================] - 0s 29ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kyJldB7FtBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "45f11448-5a75-4edd-b439-aa9cbe6d299e"
      },
      "source": [
        "model.evaluate(test_data_gen)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6419 - accuracy: 0.6909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6419159173965454, 0.6909090876579285]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P43BjAeEzf61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_circle(imgR):\n",
        "\t# root_path=\"/content/drive/My Drive/datasets/cataract dataset/training/cataract/\"\n",
        "\t# file=os.path.join(root_path,'eyeimage100.jpg')\n",
        "\t# imgR = cv2.imread(file,1)\n",
        "\t# # print(imgR)\n",
        "\ttry:\n",
        "\t\timg = cv2.cvtColor( imgR, cv2.COLOR_BGR2GRAY)\n",
        "\t\t# Median Blur at 3\n",
        "\t\timg = cv2.medianBlur(img,3)\n",
        "\t\t# Hough Transformation and numpy array circular function tracing\n",
        "\t\tcircles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,120,param1=50,param2=50,minRadius=30,maxRadius=0)\n",
        "\t\tif circles is not None:\n",
        "\t\t\tcircles = np.uint16(np.around(circles))\n",
        "\t\t\tx, y, r = circles[0,:][0]   # Coordinates and Rad\n",
        "\t\t\trows, cols = img.shape\n",
        "\t\t\txr=x\n",
        "\t\t\tyr=y\n",
        "\t\t\tprint (x,y,r)\n",
        "\t\t\t# Brightness++\n",
        "\t\t\thsv = cv2.cvtColor( imgR, cv2.COLOR_BGR2HSV)\n",
        "\t\t\th,s,v = cv2.split(hsv)\n",
        "\t\t\tv += 250\n",
        "\t\t\tfinal_hsv = cv2.merge ((h,s,v))\n",
        "\t\t\timgR = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "\t\t\timg = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)\n",
        "\t\t\t# Crop And Shift Origin : FAILED\n",
        "\t\t\timg = img[ y-int(r/2) : y+int(r/2) , x-int(r/2) : x+int(r/2)]\n",
        "\t\t\ty = r\n",
        "\t\t\tx = r\n",
        "\t\t\trows, cols = img.shape\n",
        "\t\t\t# Removing Whitespace\n",
        "\t\t\tfor i in range(cols):\n",
        "\t\t\t\tfor j in range(rows):\n",
        "\t\t\t\t\tif hypot(i-x, j-y) > r:\n",
        "\t\t\t\t\t\timg[j,i] = 0\n",
        "\t\t\tcv2.imwrite(\"iris.jpg\",img)\n",
        "\t\t\timg=img[30:2*r-30,30:2*r-30]\n",
        "\t\t\ty=r-30\n",
        "\t\t\tx=r-30\n",
        "\t\t\t#img2 = cv2.threshold(img2 , 15 , 125, cv2.THRESH_BINARY)\n",
        "\t\t\tcircles1 = cv2.HoughCircles(img ,cv2.HOUGH_GRADIENT,1,120,param1=50,param2=50,minRadius=0,maxRadius=0)\n",
        "\t\t\tcircles1 = np.uint16(np.around(circles1))\n",
        "\t\t\t#circles2 = cv2.HoughCircles(img2 ,cv2.HOUGH_GRADIENT,1,120,param1=50,param2=50,minRadius=1,maxRadius=0)\n",
        "\t\t\t#circles2 = np.uint16(np.around(circles2))\n",
        "\t\t\tx2, y2, r2 = circles1[0,:][0]\n",
        "\t\t\trows2, cols2,__ = imgR.shape\n",
        "\t\t\txn=x2+30+xr-r\n",
        "\t\t\tyn=y2+30+yr-r\n",
        "\t\t\t# print x2,y2,r2\n",
        "\t\t\tnpixels=0\n",
        "\t\t\tintensitySum=0\n",
        "\t\t\tbgrList=[]\n",
        "\t\t\tfor i in range(cols2):\n",
        "\t\t\t\tfor j in range(rows2):\n",
        "\t\t\t\t\tif hypot(i-xn, j-yn) < r2:\n",
        "\t\t\t\t\t\tnpixels+=1\n",
        "\t\t\t\t\t\tb=imgR[j,i][0]\n",
        "\t\t\t\t\t\tg=imgR[j,i][1]\n",
        "\t\t\t\t\t\tr=imgR[j,i][2]\n",
        "\t\t\t\t\t\t#calculate intensity\n",
        "\t\t\t\t\t\tintensitySum+=b\n",
        "\t\t\t\t\t\tintensitySum+=g\n",
        "\t\t\t\t\t\tintensitySum+=r\n",
        "\t\t\t\t\t\t# #calculate unformity\n",
        "\n",
        "\t\t\t\t\t\t#caculate deviation\n",
        "\t\t\t\t\t\tbgrList.append(b)\n",
        "\t\t\t\t\t\tbgrList.append(g)\n",
        "\t\t\t\t\t\tbgrList.append(r)\n",
        "\n",
        "\t\t\tintensity = (intensitySum*1.0)/(3.0*npixels)\n",
        "\t\t\tdevSum=0\n",
        "\t\t\tfor f in bgrList:\n",
        "\t\t\t\tdevSum+=(f-intensity)*(f-intensity)\n",
        "\t\t\tdevSum=sqrt(devSum)\n",
        "\t\t\tdevSum=devSum*1.0/(81*sqrt(((2*r2)*(2*r2))-1))\n",
        "\t\t\tprint( devSum,intensity)\n",
        "\t\telse:\n",
        "\t\t\tprint(\"No circle found in image\")\n",
        "\t\t#plt.imshow(img2, cmap = 'gray', interpolation = 'bicubic')\n",
        "\t\t# plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n",
        "\t\t# plt.xticks([]), plt.yticks([])\n",
        "\t\t# plt.show()\n",
        "\texcept:\n",
        "\t\treturn 0\n",
        "\treturn img"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UacqD6d5EgSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/Cataract.h5')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ5YVUauzf2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "model_new = load_model('/content/drive/My Drive/Cataract.h5')\n",
        "\n",
        "model_new.compile(loss='binary_crossentropy',\n",
        "\n",
        "              optimizer='adam',\n",
        "\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qIQW9__DtTW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "57b93cb4-6cb6-4787-fe39-9f15016cdad0"
      },
      "source": [
        "import cv2\n",
        "# Load the cascade\n",
        "eye_cascade = cv2.CascadeClassifier('/content/drive/My Drive/haarcascade_eye.xml')\n",
        "# Read the input image\n",
        "path='/content/drive/My Drive/datasets/cataract dataset/testing/cataract/'\n",
        "l=len(os.listdir(path))\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i,img_ in enumerate(os.listdir(path)):\n",
        "  img = cv2.imread(os.path.join(path,img_),1)\n",
        "  img=image_circle(img)\n",
        "  try:\n",
        "    img2=img\n",
        "    img2=np.array(img2)/255.0\n",
        "    img2.resize((32,32))\n",
        "    img2=img2.reshape((1,32,32,1))\n",
        "    classes = model_new.predict_classes(img2)\n",
        "    if classes[-1]==0:\n",
        "      classes='non cataract'\n",
        "    else:\n",
        "      classes='cataract'\n",
        "    # Display the output\n",
        "    plt.subplot(int(l/3)+1,3,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img,cmap='gray')\n",
        "    plt.xlabel(classes)\n",
        "  except:\n",
        "    pass\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "126 66 66\n",
            "152 94 82\n",
            "162 56 39\n",
            "144 92 90\n",
            "254 256 250\n",
            "0.3271412627396265 126.66856840993132\n",
            "WARNING:tensorflow:From <ipython-input-30-22b46c8702d5>:16: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"conv2d_6_input_1:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 1).\n",
            "168 68 65\n",
            "96 94 95\n",
            "254 256 250\n",
            "0.3271412627396265 126.66856840993132\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"conv2d_6_input_1:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 1).\n",
            "432 432 462\n",
            "200 94 114\n",
            "108 92 68\n",
            "396 394 425\n",
            "0.8549434974000957 138.99102802937838\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"conv2d_6_input_1:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 1).\n",
            "66 74 33\n",
            "276 274 305\n",
            "0.8366108602317877 95.52586831165348\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"conv2d_6_input_1:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 1).\n",
            "244 198 195\n",
            "0.5076757037272108 42.51321552635554\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"conv2d_6_input_1:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 1).\n",
            "94 94 85\n",
            "116 118 104\n",
            "274 272 300\n",
            "0.667984812391184 148.29424424700625\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"conv2d_6_input_1:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 1).\n",
            "114 114 113\n",
            "156 140 59\n",
            "126 122 123\n",
            "No circle found in image\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"conv2d_6_input_1:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 1).\n",
            "No circle found in image\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"conv2d_6_input_1:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 1).\n",
            "96 114 79\n",
            "114 102 101\n",
            "432 432 462\n",
            "334 342 363\n",
            "68 66 40\n",
            "150 170 150\n",
            "96 90 87\n",
            "88 156 104\n",
            "No circle found in image\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"conv2d_6_input_1:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 1).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z5t3jSgzfL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "face_cascade = cv2.CascadeClassifier('/content/drive/My Drive/haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('/content/drive/My Drive/haarcascade_eye.xml')\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    ret, img = cap.read()\n",
        "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
        "    for (x,y,w,h) in faces:\n",
        "      cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "      roi_color = img[y:y+h, x:x+w]\n",
        "    eyes = eye_cascade.detectMultiScale(roi_color)\n",
        "    for (ex,ey,ew,eh) in eyes:\n",
        "      cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "    cv2_imshow(img)\n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2RV8JjBBdeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}